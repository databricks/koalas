# Read the Docs seems having JDK 11 by default; however,
# Spark versions up to 2.4 do not support JDK 11 yet.
# Spark 3 will support it so we can remove this entire file
# when we support Spark 3.
channels:
  - conda-forge
dependencies:
  # In Read the Docs, seems whole pip-related installation is ignored when conda is used.
  - python=3.7
  - openjdk=8
  - pip
  - pip:
    - --upgrade cython
  - pip:
    # In Read the Docs, seems whole pip-related installation is ignored when conda is used.
    - -r ../requirements-dev.txt

